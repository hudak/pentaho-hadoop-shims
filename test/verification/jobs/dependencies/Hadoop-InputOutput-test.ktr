<?xml version="1.0" encoding="UTF-8"?>
<transformation>
  <info>
    <name>Hadoop-InputOutput-test</name>
    <description/>
    <extended_description/>
    <trans_version/>
    <trans_type>Normal</trans_type>
    <trans_status>0</trans_status>
    <directory>&#x2f;</directory>
    <parameters>
    </parameters>
    <log>
<trans-log-table><connection/>
<schema/>
<table/>
<size_limit_lines/>
<interval/>
<timeout_days/>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>TRANSNAME</id><enabled>Y</enabled><name>TRANSNAME</name></field><field><id>STATUS</id><enabled>Y</enabled><name>STATUS</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name><subject/></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name><subject/></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name><subject/></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name><subject/></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name><subject/></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name><subject/></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>STARTDATE</id><enabled>Y</enabled><name>STARTDATE</name></field><field><id>ENDDATE</id><enabled>Y</enabled><name>ENDDATE</name></field><field><id>LOGDATE</id><enabled>Y</enabled><name>LOGDATE</name></field><field><id>DEPDATE</id><enabled>Y</enabled><name>DEPDATE</name></field><field><id>REPLAYDATE</id><enabled>Y</enabled><name>REPLAYDATE</name></field><field><id>LOG_FIELD</id><enabled>Y</enabled><name>LOG_FIELD</name></field></trans-log-table>
<perf-log-table><connection/>
<schema/>
<table/>
<interval/>
<timeout_days/>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>SEQ_NR</id><enabled>Y</enabled><name>SEQ_NR</name></field><field><id>LOGDATE</id><enabled>Y</enabled><name>LOGDATE</name></field><field><id>TRANSNAME</id><enabled>Y</enabled><name>TRANSNAME</name></field><field><id>STEPNAME</id><enabled>Y</enabled><name>STEPNAME</name></field><field><id>STEP_COPY</id><enabled>Y</enabled><name>STEP_COPY</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>INPUT_BUFFER_ROWS</id><enabled>Y</enabled><name>INPUT_BUFFER_ROWS</name></field><field><id>OUTPUT_BUFFER_ROWS</id><enabled>Y</enabled><name>OUTPUT_BUFFER_ROWS</name></field></perf-log-table>
<channel-log-table><connection/>
<schema/>
<table/>
<timeout_days/>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>LOGGING_OBJECT_TYPE</id><enabled>Y</enabled><name>LOGGING_OBJECT_TYPE</name></field><field><id>OBJECT_NAME</id><enabled>Y</enabled><name>OBJECT_NAME</name></field><field><id>OBJECT_COPY</id><enabled>Y</enabled><name>OBJECT_COPY</name></field><field><id>REPOSITORY_DIRECTORY</id><enabled>Y</enabled><name>REPOSITORY_DIRECTORY</name></field><field><id>FILENAME</id><enabled>Y</enabled><name>FILENAME</name></field><field><id>OBJECT_ID</id><enabled>Y</enabled><name>OBJECT_ID</name></field><field><id>OBJECT_REVISION</id><enabled>Y</enabled><name>OBJECT_REVISION</name></field><field><id>PARENT_CHANNEL_ID</id><enabled>Y</enabled><name>PARENT_CHANNEL_ID</name></field><field><id>ROOT_CHANNEL_ID</id><enabled>Y</enabled><name>ROOT_CHANNEL_ID</name></field></channel-log-table>
<step-log-table><connection/>
<schema/>
<table/>
<timeout_days/>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>TRANSNAME</id><enabled>Y</enabled><name>TRANSNAME</name></field><field><id>STEPNAME</id><enabled>Y</enabled><name>STEPNAME</name></field><field><id>STEP_COPY</id><enabled>Y</enabled><name>STEP_COPY</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>LOG_FIELD</id><enabled>N</enabled><name>LOG_FIELD</name></field></step-log-table>
    </log>
    <maxdate>
      <connection/>
      <table/>
      <field/>
      <offset>0.0</offset>
      <maxdiff>0.0</maxdiff>
    </maxdate>
    <size_rowset>10000</size_rowset>
    <sleep_time_empty>50</sleep_time_empty>
    <sleep_time_full>50</sleep_time_full>
    <unique_connections>N</unique_connections>
    <feedback_shown>Y</feedback_shown>
    <feedback_size>50000</feedback_size>
    <using_thread_priorities>Y</using_thread_priorities>
    <shared_objects_file/>
    <capture_step_performance>N</capture_step_performance>
    <step_performance_capturing_delay>1000</step_performance_capturing_delay>
    <step_performance_capturing_size_limit>100</step_performance_capturing_size_limit>
    <dependencies>
    </dependencies>
    <partitionschemas>
    </partitionschemas>
    <slaveservers>
    </slaveservers>
    <clusterschemas>
    </clusterschemas>
  <created_user>-</created_user>
  <created_date>2012&#x2f;04&#x2f;12 10&#x3a;33&#x3a;58.500</created_date>
  <modified_user>-</modified_user>
  <modified_date>2012&#x2f;04&#x2f;12 10&#x3a;33&#x3a;58.500</modified_date>
  </info>
  <notepads>
  </notepads>
  <order>
  <hop> <from>Hadoop File Input</from><to>Split words to rows</to><enabled>Y</enabled> </hop>
  <hop> <from>Split words to rows</from><to>Select values</to><enabled>Y</enabled> </hop>
  <hop> <from>Select values</from><to>Add value</to><enabled>Y</enabled> </hop>
  <hop> <from>Add value</from><to>Sort rows</to><enabled>Y</enabled> </hop>
  <hop> <from>Sort rows</from><to>Group by</to><enabled>Y</enabled> </hop>
  <hop> <from>Group by</from><to>Hadoop File Output</to><enabled>Y</enabled> </hop>
  <hop> <from>Hadoop File Output</from><to>Hadoop Output</to><enabled>Y</enabled> </hop>
  <hop> <from>Hadoop Input</from><to>Dummy &#x28;do nothing&#x29;</to><enabled>Y</enabled> </hop>
  <hop> <from>Get Variables</from><to>GetFilenames.js</to><enabled>Y</enabled> </hop>
  <hop> <from>GetFilenames.js</from><to>Hadoop File Input</to><enabled>Y</enabled> </hop>
  </order>
  <step>
    <name>Add value</name>
    <type>Constant</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <fields>
      <field>
        <name>count</name>
        <type>Integer</type>
        <format/>
        <currency/>
        <decimal/>
        <group/>
        <nullif>1</nullif>
        <length>-1</length>
        <precision>-1</precision>
      </field>
    </fields>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>724</xloc>
      <yloc>297</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Dummy &#x28;do nothing&#x29;</name>
    <type>Dummy</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>213</xloc>
      <yloc>142</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Group by</name>
    <type>GroupBy</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
      <all_rows>N</all_rows>
      <ignore_aggregate>N</ignore_aggregate>
      <field_ignore/>
      <directory>&#x25;&#x25;java.io.tmpdir&#x25;&#x25;</directory>
      <prefix>grp</prefix>
      <add_linenr>N</add_linenr>
      <linenr_fieldname/>
      <give_back_row>N</give_back_row>
      <group>
        <field>
          <name>word</name>
        </field>
      </group>
      <fields>
        <field>
          <aggregate>sum</aggregate>
          <subject>count</subject>
          <type>SUM</type>
          <valuefield/>
        </field>
      </fields>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>801</xloc>
      <yloc>409</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Hadoop File Input</name>
    <type>HadoopFileInputPlugin</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <accept_filenames>Y</accept_filenames>
    <passing_through_fields>N</passing_through_fields>
    <accept_field>filename</accept_field>
    <accept_stepname>GetFilenames.js</accept_stepname>
    <separator>&#x3b;</separator>
    <enclosure>&#x22;</enclosure>
    <enclosure_breaks>N</enclosure_breaks>
    <escapechar/>
    <header>Y</header>
    <nr_headerlines>1</nr_headerlines>
    <footer>N</footer>
    <nr_footerlines>1</nr_footerlines>
    <line_wrapped>N</line_wrapped>
    <nr_wraps>1</nr_wraps>
    <layout_paged>N</layout_paged>
    <nr_lines_per_page>80</nr_lines_per_page>
    <nr_lines_doc_header>0</nr_lines_doc_header>
    <noempty>Y</noempty>
    <include>N</include>
    <include_field/>
    <rownum>N</rownum>
    <rownumByFile>N</rownumByFile>
    <rownum_field/>
    <format>Unix</format>
    <encoding/>
    <add_to_result_filenames>Y</add_to_result_filenames>
    <file>
      <name/>
      <filemask/>
      <exclude_filemask/>
      <file_required>N</file_required>
      <include_subfolders>N</include_subfolders>
      <type>CSV</type>
      <compression>None</compression>
    </file>
    <filters>
    </filters>
    <fields>
      <field>
        <name>The_Project_Gutenberg_EBook_of_The_Outline_of_Science,_Vol._1_&#x28;of_4&#x29;,_by</name>
        <type>String</type>
        <format/>
        <currency/>
        <decimal/>
        <group/>
        <nullif/>
        <ifnull/>
        <position>-1</position>
        <length>100</length>
        <precision>-1</precision>
        <trim_type>none</trim_type>
        <repeat>N</repeat>
      </field>
    </fields>
    <limit>0</limit>
    <error_ignored>N</error_ignored>
    <skip_bad_files>N</skip_bad_files>
    <file_error_field/>
    <file_error_message_field/>
    <error_line_skipped>N</error_line_skipped>
    <error_count_field/>
    <error_fields_field/>
    <error_text_field/>
    <bad_line_files_destination_directory/>
    <bad_line_files_extension>warning</bad_line_files_extension>
    <error_line_files_destination_directory/>
    <error_line_files_extension>error</error_line_files_extension>
    <line_number_files_destination_directory/>
    <line_number_files_extension>line</line_number_files_extension>
    <date_format_lenient>Y</date_format_lenient>
    <date_format_locale>en_US</date_format_locale>
    <shortFileFieldName/>
    <pathFieldName/>
    <hiddenFieldName/>
    <lastModificationTimeFieldName/>
    <uriNameFieldName/>
    <rootUriNameFieldName/>
    <extensionFieldName/>
    <sizeFieldName/>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>381</xloc>
      <yloc>381</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Hadoop File Output</name>
    <type>HadoopFileOutputPlugin</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <separator>&#x3b;</separator>
    <enclosure>&#x22;</enclosure>
    <enclosure_forced>N</enclosure_forced>
    <enclosure_fix_disabled>N</enclosure_fix_disabled>
    <header>Y</header>
    <footer>N</footer>
    <format>Unix</format>
    <compression>None</compression>
    <encoding/>
    <endedLine/>
    <fileNameInField>N</fileNameInField>
    <fileNameField/>
    <create_parent_folder>Y</create_parent_folder>
    <file>
      <name>&#x24;&#x7b;hadoop.scheme&#x7d;&#x3a;&#x2f;&#x2f;&#x24;&#x7b;hadoop.hostname&#x7d;&#x3a;&#x24;&#x7b;hadoop.port&#x7d;&#x2f;wordcount-hdfs-output&#x2f;output-&#x24;&#x7b;Internal.Hadoop.TaskId&#x7d;</name>
      <is_command>N</is_command>
      <servlet_output>N</servlet_output>
      <do_not_open_new_file_init>N</do_not_open_new_file_init>
      <extention>txt</extention>
      <append>N</append>
      <split>N</split>
      <haspartno>N</haspartno>
      <add_date>N</add_date>
      <add_time>N</add_time>
      <SpecifyFormat>Y</SpecifyFormat>
      <date_time_format>MM-dd-yyyy-HH-mm-ss-SSS</date_time_format>
      <add_to_result_filenames>Y</add_to_result_filenames>
      <pad>N</pad>
      <fast_dump>N</fast_dump>
      <splitevery>0</splitevery>
    </file>
    <fields>
      <field>
        <name>word</name>
        <type>String</type>
        <format/>
        <currency/>
        <decimal/>
        <group/>
        <nullif/>
        <trim_type>none</trim_type>
        <length>-1</length>
        <precision>-1</precision>
      </field>
      <field>
        <name>sum</name>
        <type>Integer</type>
        <format/>
        <currency/>
        <decimal/>
        <group/>
        <nullif/>
        <trim_type>none</trim_type>
        <length>-1</length>
        <precision>0</precision>
      </field>
    </fields>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>936</xloc>
      <yloc>404</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Hadoop Input</name>
    <type>HadoopEnterPlugin</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <fields>      <field>        <name>key</name>
        <type>String</type>
        <length>0</length>
        <precision>2</precision>
      </field>      <field>        <name>value</name>
        <type>String</type>
        <length>0</length>
        <precision>2</precision>
      </field>    </fields>     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>100</xloc>
      <yloc>262</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Hadoop Output</name>
    <type>HadoopExitPlugin</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <outkeyfieldname>word</outkeyfieldname>
    <outvaluefieldname>sum</outvaluefieldname>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>1083</xloc>
      <yloc>259</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Select values</name>
    <type>SelectValues</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <fields>        <select_unspecified>N</select_unspecified>
      <remove>        <name>The_Project_Gutenberg_EBook_of_The_Outline_of_Science,_Vol._1_&#x28;of_4&#x29;,_by</name>
      </remove>    </fields>     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>675</xloc>
      <yloc>428</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Sort rows</name>
    <type>SortRows</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
      <directory>&#x25;&#x25;java.io.tmpdir&#x25;&#x25;</directory>
      <prefix>out</prefix>
      <sort_size>1000000</sort_size>
      <free_memory/>
      <compress>N</compress>
      <compress_variable/>
      <unique_rows>N</unique_rows>
    <fields>
      <field>
        <name>word</name>
        <ascending>Y</ascending>
        <case_sensitive>N</case_sensitive>
      </field>
      <field>
        <name>count</name>
        <ascending>N</ascending>
        <case_sensitive>N</case_sensitive>
      </field>
    </fields>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>837</xloc>
      <yloc>289</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Split words to rows</name>
    <type>SplitFieldToRows3</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
   <splitfield>The_Project_Gutenberg_EBook_of_The_Outline_of_Science,_Vol._1_&#x28;of_4&#x29;,_by</splitfield>
   <delimiter> </delimiter>
   <newfield>word</newfield>
   <rownum>N</rownum>
   <rownum_field/>
   <resetrownumber>Y</resetrownumber>
   <delimiter_is_regex>N</delimiter_is_regex>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>571</xloc>
      <yloc>353</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>GetFilenames.js</name>
    <type>Script</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <jsScripts>      <jsScript>        <jsScript_type>0</jsScript_type>
        <jsScript_name>Script 1</jsScript_name>
        <jsScript_script>var hadoopUrl &#x3d; hadoop_scheme &#x2b; &#x27;&#x3a;&#x2f;&#x2f;&#x27; &#x2b; hadoop_hostname &#x2b; &#x27;&#x3a;&#x27; &#x2b; hadoop_port &#x2b; &#x27;&#x2f;wordcount&#x2f;input&#x27;&#x3b;&#xa;var fsManager &#x3d; org.pentaho.di.core.vfs.KettleVFS.getInstance&#x28;&#x29;.getFileSystemManager&#x28;&#x29;&#x3b;&#xa;var inputFolder &#x3d; fsManager.resolveFile&#x28;hadoopUrl&#x29;&#x3b;&#xa;&#xa;var files &#x3d; java.util.Arrays.asList&#x28;inputFolder.findFiles&#x28;new org.apache.commons.vfs.FileSelector&#x28;&#x7b;&#xa;  includeFile&#x3a; function&#x28;info&#x29; &#x7b; return info.getFile&#x28;&#x29;.getName&#x28;&#x29;.getBaseName&#x28;&#x29;.endsWith&#x28;&#x27;.txt&#x27;&#x29;&#x3b; &#x7d;,&#xa;  traverseDescendents&#x3a; function&#x28;info&#x29; &#x7b; return true&#x3b;&#x7d;&#xa;&#x7d;&#x29;&#x29;&#x29;&#x3b;&#xa;&#xa;for &#x28;var i &#x3d; 0&#x3b; i &#x3c; files.size&#x28;&#x29;&#x3b; i&#x2b;&#x2b;&#x29; &#x7b;&#xa;    var file &#x3d; files.get&#x28;i&#x29;&#x3b;&#xa;    var newRow &#x3d; org.pentaho.di.core.row.RowDataUtil.createResizedCopy&#x28;row, _step_.getOutputRowMeta&#x28;&#x29;.size&#x28;&#x29;&#x29;&#x3b;&#xa;    var rowIndex &#x3d; _step_.getInputRowMeta&#x28;&#x29;.size&#x28;&#x29;&#x3b;&#xa;&#xa;    newRow&#x5b;rowIndex&#x2b;&#x2b;&#x5d; &#x3d; file.getURL&#x28;&#x29;.toString&#x28;&#x29;&#x3b;&#xa;&#xa;    _step_.putRow&#x28;_step_.getOutputRowMeta&#x28;&#x29;, newRow&#x29;&#x3b;&#xa;&#x7d;&#xa;&#xa;trans_Status &#x3d; SKIP_TRANSFORMATION</jsScript_script>
      </jsScript>    </jsScripts>    <fields>      <field>        <name>filename</name>
        <rename>filename</rename>
        <type>String</type>
        <length>-1</length>
        <precision>-1</precision>
        <replace>N</replace>
      </field>    </fields>     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>202</xloc>
      <yloc>379</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step>
    <name>Get Variables</name>
    <type>GetVariable</type>
    <description/>
    <distribute>Y</distribute>
    <copies>1</copies>
         <partitioning>
           <method>none</method>
           <schema_name/>
           </partitioning>
    <fields>
      <field>
        <name>hadoop_hostname</name>
        <variable>&#x24;&#x7b;hadoop.hostname&#x7d;</variable>
        <type>-</type>
        <format/>
        <currency/>
        <decimal/>
        <group/>
        <length>-1</length>
        <precision>-1</precision>
        <trim_type>none</trim_type>
      </field>
      <field>
        <name>hadoop_port</name>
        <variable>&#x24;&#x7b;hadoop.port&#x7d;</variable>
        <type>-</type>
        <format/>
        <currency/>
        <decimal/>
        <group/>
        <length>-1</length>
        <precision>-1</precision>
        <trim_type>none</trim_type>
      </field>
      <field>
        <name>hadoop_scheme</name>
        <variable>&#x24;&#x7b;hadoop.scheme&#x7d;</variable>
        <type>-</type>
        <format/>
        <currency/>
        <decimal/>
        <group/>
        <length>-1</length>
        <precision>-1</precision>
        <trim_type>none</trim_type>
      </field>
    </fields>
     <cluster_schema/>
 <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
      <xloc>68</xloc>
      <yloc>377</yloc>
      <draw>Y</draw>
      </GUI>
    </step>

  <step_error_handling>
  </step_error_handling>
   <slave-step-copy-partition-distribution>
</slave-step-copy-partition-distribution>
   <slave_transformation>N</slave_transformation>
</transformation>
